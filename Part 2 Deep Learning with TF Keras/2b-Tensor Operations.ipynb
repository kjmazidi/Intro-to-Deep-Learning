{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1c-Tensor Operations.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"CLoQ6pqCJ2bW"},"source":["<sup>This notebook is adapted from code from *Deep Learning with Python 2nd edition* by Francois Challot. \n","\n","<sup>See the original code in the books' companion [GitHub](https://github.com/fchollet/deep-learning-with-python-notebooks).  Find the book here: [Amazon Link](https://www.amazon.com/Learning-Python-Second-Fran-C3-A7ois-Chollet-dp-1617296864/dp/1617296864/)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OqlOW96OJ2bZ"},"source":["## The gears of neural networks: tensor operations\n","\n","These code snippets from Francois Challot provide pseudocode to how tensor operations work conceptually. Under the hood of TennsorFlow, the optimized code performs similar functionality. "]},{"cell_type":"markdown","metadata":{"id":"GXDbeoFyJ2bZ"},"source":["### Element-wise operations\n","\n","The naive add and relu functions compute add and relu activation in a simple way to demonstrate the concepts of vector operations. \n","\n","The third and fourth code chunks below compare the naive Python code to NumPy code to show the efficiency of operations in NumPy, "]},{"cell_type":"code","metadata":{"id":"XLFamGeUKjpM"},"source":["import numpy as np\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FuP4rMeJ2ba"},"source":["def naive_relu(x):\n","    assert len(x.shape) == 2\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] = max(x[i, j], 0)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiR1RNBhJ2bb"},"source":["def naive_add(x, y):\n","    assert len(x.shape) == 2\n","    assert x.shape == y.shape\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] += y[i, j]\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFQHd67dJ2bb","executionInfo":{"status":"ok","timestamp":1636049784126,"user_tz":300,"elapsed":171,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"94ff22ca-bcb7-4967-ee0f-d3017123b08d"},"source":["x = np.random.random((20, 100))\n","y = np.random.random((20, 100))\n","\n","t0 = time.time()\n","for _ in range(1000):\n","    z = x + y\n","    z = np.maximum(z, 0.)\n","print(\"Took: {0:.2f} s\".format(time.time() - t0))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Took: 0.01 s\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVFb3Y6EJ2bc","executionInfo":{"status":"ok","timestamp":1636049790285,"user_tz":300,"elapsed":2977,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"d94faee1-9fd9-4c7b-926e-39cd3b8438ea"},"source":["t0 = time.time()\n","for _ in range(1000):\n","    z = naive_add(x, y)\n","    z = naive_relu(z)\n","print(\"Took: {0:.2f} s\".format(time.time() - t0))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Took: 2.79 s\n"]}]},{"cell_type":"markdown","metadata":{"id":"pMx-e6a4J2bc"},"source":["### Broadcasting\n","\n","When copying a smaller array to a larger one, NumPy will \"broadcast\", meaning the smaller array is copied as many times as needed to fill the larger array. \n","\n","This has two steps:\n","* an axes to the smaller tensor to match the ndim of the larger tensor\n","* repeat the smaller tensor along the new axes to match the shape of the larger tensor\n","\n","\n","The expand\\_dims function is deprecated, so another way to expand the dims is shown below. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OS7KCUhkJ2bd","executionInfo":{"status":"ok","timestamp":1636050366276,"user_tz":300,"elapsed":197,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"cfe94c99-0ec1-4fac-d715-21c6817a0d53"},"source":["X = np.random.random((32, 10))\n","y_original = np.random.random((10,))\n","y_original.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10,)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCzmVSH3J2bd","executionInfo":{"status":"ok","timestamp":1636050368331,"user_tz":300,"elapsed":171,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"f6f9751d-f0c6-4f37-841d-ad583be423f2"},"source":["y_expanded = np.expand_dims(y_original, axis=0)\n","y_expanded.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 10)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9eB-lM_L__3","executionInfo":{"status":"ok","timestamp":1636050372485,"user_tz":300,"elapsed":170,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"5d2e856b-ab77-423d-b0ab-09c2343f65d0"},"source":["# expand_dims is deprecated\n","# use this instead\n","\n","y = y[np.newaxis, :]  # put : where you want the new axis\n","y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 32, 10)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJSIeVq3J2be","executionInfo":{"status":"ok","timestamp":1636050375975,"user_tz":300,"elapsed":185,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"fde55e2d-595c-4bb4-8587-6ccd6270f66b"},"source":["Y = np.concatenate([y] * 32, axis=0)\n","Y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 32, 10)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"-RhngFRcJ2be"},"source":["def naive_add_matrix_and_vector(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 1\n","    assert x.shape[1] == y.shape[0]\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] += y[j]\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHlLJ0yUMlhx","executionInfo":{"status":"ok","timestamp":1636050414166,"user_tz":300,"elapsed":165,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"1dc733ed-20ae-4e1a-d7a3-0c6442935d71"},"source":["result = naive_add_matrix_and_vector(X, y_original)\n","result.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 10)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"L-lPC2G-J2bf"},"source":["### Tensor product\n","\n","Below are more functions that serve as pseudocode for tensor operations such as dot products. "]},{"cell_type":"code","metadata":{"id":"-FhKhkqeJ2be"},"source":["import numpy as np\n","x = np.random.random((64, 3, 32, 10))\n","y = np.random.random((32, 10))\n","z = np.maximum(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyGVHTTtJ2bf"},"source":["x = np.random.random((32,))\n","y = np.random.random((32,))\n","z = np.dot(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZV3e_B7VJ2bf"},"source":["def naive_vector_dot(x, y):\n","    assert len(x.shape) == 1\n","    assert len(y.shape) == 1\n","    assert x.shape[0] == y.shape[0]\n","    z = 0.\n","    for i in range(x.shape[0]):\n","        z += x[i] * y[i]\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuBwENiXJ2bf"},"source":["def naive_matrix_vector_dot(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 1\n","    assert x.shape[1] == y.shape[0]\n","    z = np.zeros(x.shape[0])\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            z[i] += x[i, j] * y[j]\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EO76nX7CJ2bg"},"source":["def naive_matrix_vector_dot(x, y):\n","    z = np.zeros(x.shape[0])\n","    for i in range(x.shape[0]):\n","        z[i] = naive_vector_dot(x[i, :], y)\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8Edy0ruJ2bg"},"source":["def naive_matrix_dot(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 2\n","    assert x.shape[1] == y.shape[0]\n","    z = np.zeros((x.shape[0], y.shape[1]))\n","    for i in range(x.shape[0]):\n","        for j in range(y.shape[1]):\n","            row_x = x[i, :]\n","            column_y = y[:, j]\n","            z[i, j] = naive_vector_dot(row_x, column_y)\n","    return z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b-KpZwAWJ2bg"},"source":["### Tensor reshaping"]},{"cell_type":"code","metadata":{"id":"QIsaJAmmJ2bg"},"source":["train_images = train_images.reshape((60000, 28 * 28))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsBSKoDsJ2bh"},"source":["x = np.array([[0., 1.],\n","             [2., 3.],\n","             [4., 5.]])\n","x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8M70DgdJ2bh"},"source":["x = x.reshape((6, 1))\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WS8ocE7mJ2bh"},"source":["x = np.zeros((300, 20))\n","x = np.transpose(x)\n","x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"njesF-p_J2bh"},"source":["#### The gradient tape in TensorFlow\n","\n","TensorFlow implements automatic differentiation by means of computation graphs. The gradients are compositions of differentiable tensor operations. Specifying the forward pass also defines how the gradients are computed. \n","\n","The GradientTape functionality in TensorFlow records the tensor operations that run inside it's scope. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPcwF-m_J2bh","executionInfo":{"status":"ok","timestamp":1636072543351,"user_tz":300,"elapsed":230,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"70712fa6-31f1-4251-a7ce-56e1a4685a5b"},"source":["import tensorflow as tf\n","x = tf.Variable(0.)\n","with tf.GradientTape() as tape:\n","    y = 2 * x + 3\n","grad_of_y_wrt_x = tape.gradient(y, x)\n","\n","print(grad_of_y_wrt_x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(2.0, shape=(), dtype=float32)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mpq2tccZJ2bi","executionInfo":{"status":"ok","timestamp":1636072573810,"user_tz":300,"elapsed":182,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"81fe100d-8a6f-483f-a90f-45f8904a737f"},"source":["x = tf.Variable(tf.random.uniform((2, 2)))\n","with tf.GradientTape() as tape:\n","    y = 2 * x + 3\n","grad_of_y_wrt_x = tape.gradient(y, x)\n","\n","print(grad_of_y_wrt_x)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[2. 2.]\n"," [2. 2.]], shape=(2, 2), dtype=float32)\n"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ijSDBAz2J2bi","executionInfo":{"status":"ok","timestamp":1636072711739,"user_tz":300,"elapsed":225,"user":{"displayName":"Karen Janice Mazidi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRxWMd1kdCCDAxi9gcTgAt8fOYqu1fFKGVTIWH8g=s64","userId":"15149885104950584541"}},"outputId":"c5602ff1-b51d-4ac8-bce9-cc69c32fc640"},"source":["W = tf.Variable(tf.random.uniform((2, 2)))\n","b = tf.Variable(tf.zeros((2,)))\n","x = tf.random.uniform((2, 2))\n","with tf.GradientTape() as tape:\n","    y = tf.matmul(x, W) + b\n","grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n","\n","print('W=', W)\n","print('b=', b)\n","print('x=', x)\n","print('\\nGrad:', grad_of_y_wrt_W_and_b)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["W= <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[0.5864936, 0.5392288],\n","       [0.0373162, 0.5145111]], dtype=float32)>\n","b= <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>\n","x= tf.Tensor(\n","[[0.7531737  0.55128396]\n"," [0.40519285 0.30589557]], shape=(2, 2), dtype=float32)\n","\n","Grad: [<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[1.1583666, 1.1583666],\n","       [0.8571795, 0.8571795]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"]}]}]}