{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1d-Custom-layer-activation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b_hotuDhho_f"},"source":["# Activation in Custom Layers\n","\n","In this lab, we extend our knowledge of building custom layers by adding an activation parameter. The implementation is pretty straightforward as you'll see below."]},{"cell_type":"code","metadata":{"id":"DpioxwFXD9Is","executionInfo":{"status":"ok","timestamp":1649174579216,"user_tz":300,"elapsed":6112,"user":{"displayName":"Karen Janice Mazidi","userId":"15149885104950584541"}}},"source":["# imports\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqPwtJjDho_k"},"source":["## Adding an activation layer\n","\n","To use the built-in activations in Keras, we can specify an `activation` parameter in the `__init__()` method of our custom layer class. From there, we can initialize it by using the `tf.keras.activations.get()` method. This takes in a string identifier that corresponds to one of the [available activations](https://keras.io/api/layers/activations/#available-activations) in Keras. Next, you can now pass in the forward computation to this activation in the `call()` method."]},{"cell_type":"code","metadata":{"id":"jnVrzRT6BPWl","executionInfo":{"status":"ok","timestamp":1649174579217,"user_tz":300,"elapsed":4,"user":{"displayName":"Karen Janice Mazidi","userId":"15149885104950584541"}}},"source":["class SimpleDense(Layer):\n","\n","    # add an activation parameter\n","    def __init__(self, units=32, activation=None):\n","        super(SimpleDense, self).__init__()\n","        self.units = units\n","        \n","        # define the activation to get from the built-in activation layers in Keras\n","        self.activation = tf.keras.activations.get(activation)\n","\n","\n","    def build(self, input_shape):\n","        w_init = tf.random_normal_initializer()\n","        self.w = tf.Variable(name=\"kernel\",\n","            initial_value=w_init(shape=(input_shape[-1], self.units),\n","                                 dtype='float32'),\n","            trainable=True)\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(name=\"bias\",\n","            initial_value=b_init(shape=(self.units,), dtype='float32'),\n","            trainable=True)\n","        super().build(input_shape)\n","\n","\n","    def call(self, inputs):\n","        \n","        # pass the computation to the activation layer\n","        return self.activation(tf.matmul(inputs, self.w) + self.b)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQnzDzWVho_l"},"source":["We can now pass in an activation parameter to our custom layer. The string identifier is mostly the same as the function name so 'relu' below will get `tf.keras.activations.relu`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwTPJT4DkTyW","executionInfo":{"status":"ok","timestamp":1649174629506,"user_tz":300,"elapsed":22930,"user":{"displayName":"Karen Janice Mazidi","userId":"15149885104950584541"}},"outputId":"22b281da-c68b-4ca6-c1e0-a9c6cff132a9"},"source":["mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),\n","    SimpleDense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=5)\n","model.evaluate(x_test, y_test)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.2985 - accuracy: 0.9134\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1430 - accuracy: 0.9571\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1074 - accuracy: 0.9678\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0867 - accuracy: 0.9735\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0739 - accuracy: 0.9772\n","313/313 [==============================] - 1s 1ms/step - loss: 0.0740 - accuracy: 0.9788\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.0739746242761612, 0.9787999987602234]"]},"metadata":{},"execution_count":3}]}]}